{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6784029b",
   "metadata": {},
   "source": [
    "## Santhosh S\n",
    "## 225229133\n",
    "## PDL lab 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "222a8f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2eb6641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee01a871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5b14714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53a4bd2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you want to achieve greatness stop asking f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Things work out best for those who make the be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To live a creative life, we must lose our fear...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are not willing to risk the usual you w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trust because you are willing to accept the ri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Take up one idea. Make that one idea your life...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>All our dreams can come true if we have the co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Good things come to people who wait, but bette...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>If you do what you always did, you will get wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Success is walking from failure to failure wit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Just when the caterpillar thought the world wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Successful entrepreneurs are givers and not ta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Whenever you see a successful person you only ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Opportunities don't happen, you create them. ~...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Try not to become a person of success, but rat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Great minds discuss ideas; average minds discu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I have not failed. I've just found 10,000 ways...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>If you don't value your time, neither will oth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A successful man is one who can lay a firm fou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>No one can make you feel inferior without your...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Everything happens for a reason. Sometimes th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Every dead body on Mt. Everest was once a hig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Light travels faster than sound. This is why ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Just because we accept you as you are doesnt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Idiocy  never underestimate the power of stu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>If life doesnt break you today, dont worry....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>People who say theyll give 110% dont unders...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A thousand-mile journey starts with one step....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Two things are infinite: the universe and hum...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>If you never try anything new, youll miss ou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>If at first, you don't succeed, try, try agai...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>It could be that your purpose in life is to s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Today is the first day of the rest of your l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Just because you are unique doesn't mean you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Oh, you hate your job? Why didnt you say so?...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>I am free of all prejudice. I hate everyone e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Always remember that you are absolutely uniqu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Multitasking  the art of doing twice as much...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>The story so far: In the beginning, the Unive...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Life is pain. Anyone who says otherwise is se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Quotes  Labels\n",
       "0   If you want to achieve greatness stop asking f...       1\n",
       "1   Things work out best for those who make the be...       1\n",
       "2   To live a creative life, we must lose our fear...       1\n",
       "3   If you are not willing to risk the usual you w...       1\n",
       "4   Trust because you are willing to accept the ri...       1\n",
       "5   Take up one idea. Make that one idea your life...       1\n",
       "6   All our dreams can come true if we have the co...       1\n",
       "7   Good things come to people who wait, but bette...       1\n",
       "8   If you do what you always did, you will get wh...       1\n",
       "9   Success is walking from failure to failure wit...       1\n",
       "10  Just when the caterpillar thought the world wa...       1\n",
       "11  Successful entrepreneurs are givers and not ta...       1\n",
       "12  Whenever you see a successful person you only ...       1\n",
       "13  Opportunities don't happen, you create them. ~...       1\n",
       "14  Try not to become a person of success, but rat...       1\n",
       "15  Great minds discuss ideas; average minds discu...       1\n",
       "16  I have not failed. I've just found 10,000 ways...       1\n",
       "17  If you don't value your time, neither will oth...       1\n",
       "18  A successful man is one who can lay a firm fou...       1\n",
       "19  No one can make you feel inferior without your...       1\n",
       "20  Everything happens for a reason. Sometimes th...       0\n",
       "21  Every dead body on Mt. Everest was once a hig...       0\n",
       "22  Light travels faster than sound. This is why ...       0\n",
       "23  Just because we accept you as you are doesnt...       0\n",
       "24  Idiocy  never underestimate the power of stu...       0\n",
       "25  If life doesnt break you today, dont worry....       0\n",
       "26  People who say theyll give 110% dont unders...       0\n",
       "27  A thousand-mile journey starts with one step....       0\n",
       "28  Two things are infinite: the universe and hum...       0\n",
       "29  If you never try anything new, youll miss ou...       0\n",
       "30  If at first, you don't succeed, try, try agai...       0\n",
       "31  It could be that your purpose in life is to s...       0\n",
       "32   Today is the first day of the rest of your l...       0\n",
       "33  Just because you are unique doesn't mean you ...       0\n",
       "34  Oh, you hate your job? Why didnt you say so?...       0\n",
       "35  I am free of all prejudice. I hate everyone e...       0\n",
       "36  Always remember that you are absolutely uniqu...       0\n",
       "37  Multitasking  the art of doing twice as much...       0\n",
       "38  The story so far: In the beginning, the Unive...       0\n",
       "39  Life is pain. Anyone who says otherwise is se...       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=pd.read_csv('motivation.csv',encoding='latin')\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "501fe6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Labels\n",
      "count  40.00000\n",
      "mean    0.50000\n",
      "std     0.50637\n",
      "min     0.00000\n",
      "25%     0.00000\n",
      "50%     0.50000\n",
      "75%     1.00000\n",
      "max     1.00000\n"
     ]
    }
   ],
   "source": [
    "print(f.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b54fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     If you want to achieve greatness stop asking f...\n",
      "1     Things work out best for those who make the be...\n",
      "2     To live a creative life, we must lose our fear...\n",
      "3     If you are not willing to risk the usual you w...\n",
      "4     Trust because you are willing to accept the ri...\n",
      "5     Take up one idea. Make that one idea your life...\n",
      "6     All our dreams can come true if we have the co...\n",
      "7     Good things come to people who wait, but bette...\n",
      "8     If you do what you always did, you will get wh...\n",
      "9     Success is walking from failure to failure wit...\n",
      "10    Just when the caterpillar thought the world wa...\n",
      "11    Successful entrepreneurs are givers and not ta...\n",
      "12    Whenever you see a successful person you only ...\n",
      "13    Opportunities don't happen, you create them. ~...\n",
      "14    Try not to become a person of success, but rat...\n",
      "15    Great minds discuss ideas; average minds discu...\n",
      "16    I have not failed. I've just found 10,000 ways...\n",
      "17    If you don't value your time, neither will oth...\n",
      "18    A successful man is one who can lay a firm fou...\n",
      "19    No one can make you feel inferior without your...\n",
      "20    Everything happens for a reason. Sometimes th...\n",
      "21    Every dead body on Mt. Everest was once a hig...\n",
      "22    Light travels faster than sound. This is why ...\n",
      "23    Just because we accept you as you are doesnt...\n",
      "24    Idiocy  never underestimate the power of stu...\n",
      "25    If life doesnt break you today, dont worry....\n",
      "26    People who say theyll give 110% dont unders...\n",
      "27    A thousand-mile journey starts with one step....\n",
      "28    Two things are infinite: the universe and hum...\n",
      "29    If you never try anything new, youll miss ou...\n",
      "30    If at first, you don't succeed, try, try agai...\n",
      "31    It could be that your purpose in life is to s...\n",
      "32     Today is the first day of the rest of your l...\n",
      "33    Just because you are unique doesn't mean you ...\n",
      "34    Oh, you hate your job? Why didnt you say so?...\n",
      "35    I am free of all prejudice. I hate everyone e...\n",
      "36    Always remember that you are absolutely uniqu...\n",
      "37    Multitasking  the art of doing twice as much...\n",
      "38    The story so far: In the beginning, the Unive...\n",
      "39    Life is pain. Anyone who says otherwise is se...\n",
      "Name: Quotes, dtype: object\n",
      "Quotes    If you want to achieve greatness stop asking f...\n",
      "Labels                                                    1\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(f['Quotes'])\n",
    "print(f.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b945af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dc43d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06ca5e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1678c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "anger_quotes = f[f['Labels'] == 0]\n",
    "happiness_quotes = f[f['Labels'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c0598ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03c3edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0652f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf_vectorizer.fit_transform(f['Quotes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a17f1acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c2cd008",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba7b6b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         000        10       110  abandoned  absolutely    accept   achieve  \\\n",
      "0   0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.398968   \n",
      "1   0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "2   0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "3   0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "4   0.000000  0.000000  0.000000   0.000000    0.000000  0.370196  0.000000   \n",
      "5   0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "6   0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "7   0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "8   0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "9   0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "10  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "11  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "12  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "13  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "14  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "15  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "16  0.333941  0.333941  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "17  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "18  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "19  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "20  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "21  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "22  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "23  0.000000  0.000000  0.000000   0.370902    0.000000  0.333496  0.000000   \n",
      "24  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "25  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "26  0.000000  0.000000  0.402248   0.000000    0.000000  0.000000  0.000000   \n",
      "27  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "28  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "29  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "30  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "31  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "32  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "33  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "34  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "35  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "36  0.000000  0.000000  0.000000   0.000000    0.398968  0.000000  0.000000   \n",
      "37  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "38  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "39  0.000000  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000   \n",
      "\n",
      "       adams      alan    albert  ...  william   willing   winston       won  \\\n",
      "0   0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "1   0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "2   0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "3   0.000000  0.000000  0.000000  ...  0.00000  0.349545  0.000000  0.000000   \n",
      "4   0.000000  0.000000  0.000000  ...  0.00000  0.370196  0.000000  0.000000   \n",
      "5   0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "6   0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "7   0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "8   0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "9   0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.321331  0.000000   \n",
      "10  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "11  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "12  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "13  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "14  0.000000  0.000000  0.313339  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "15  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "16  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.333941   \n",
      "17  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "18  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "19  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "20  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "21  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "22  0.000000  0.308991  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "23  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "24  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "25  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "26  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "27  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "28  0.000000  0.000000  0.291175  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "29  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "30  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "31  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "32  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "33  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "34  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "35  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "36  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "37  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "38  0.287589  0.000000  0.000000  ...  0.00000  0.000000  0.000000  0.000000   \n",
      "39  0.000000  0.000000  0.000000  ...  0.42917  0.000000  0.000000  0.000000   \n",
      "\n",
      "      wooden      work     world     worry     wrong  yesterday  \n",
      "0   0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "1   0.287772  0.476317  0.000000  0.000000  0.000000   0.000000  \n",
      "2   0.000000  0.000000  0.000000  0.000000  0.418427   0.000000  \n",
      "3   0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "4   0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "5   0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "6   0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "7   0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "8   0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "9   0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "10  0.000000  0.000000  0.370565  0.000000  0.000000   0.000000  \n",
      "11  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "12  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "13  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "14  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "15  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "16  0.000000  0.276367  0.000000  0.000000  0.000000   0.000000  \n",
      "17  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "18  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "19  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "20  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "21  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "22  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "23  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "24  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "25  0.000000  0.000000  0.000000  0.406661  0.000000   0.000000  \n",
      "26  0.000000  0.332898  0.000000  0.000000  0.000000   0.000000  \n",
      "27  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "28  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "29  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "30  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "31  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "32  0.000000  0.000000  0.000000  0.000000  0.000000   0.406685  \n",
      "33  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "34  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "35  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "36  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "37  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "38  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "39  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  \n",
      "\n",
      "[40 rows x 248 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d079582e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000' '10' '110' 'abandoned' 'absolutely' 'accept' 'achieve' 'adams'\n",
      " 'alan' 'albert' 'angry' 'anonymous' 'appear' 'art' 'ashleigh' 'asking'\n",
      " 'average' 'away' 'bad' 'bar' 'beginning' 'best' 'better' 'body' 'brain'\n",
      " 'break' 'breaking' 'bricks' 'bright' 'brilliant' 'brinkley' 'butterfly'\n",
      " 'called' 'calm' 'carey' 'caterpillar' 'certain' 'charging' 'chris'\n",
      " 'churchill' 'come' 'consent' 'courage' 'create' 'created' 'creative'\n",
      " 'damn' 'david' 'day' 'dead' 'decisions' 'did' 'didn' 'disappointments'\n",
      " 'discuss' 'disney' 'ditch' 'does' 'doesn' 'doing' 'don' 'douglas' 'dream'\n",
      " 'dreams' 'drew' 'dundes' 'edison' 'einstein' 'eleanor' 'ending' 'energy'\n",
      " 'enthusiasm' 'entrepreneurs' 'equally' 'events' 'everest' 'everybody'\n",
      " 'failed' 'failure' 'falling' 'far' 'faster' 'fear' 'feel' 'fields' 'firm'\n",
      " 'fool' 'foundation' 'free' 'garst' 'givers' 'giving' 'glories' 'goldman'\n",
      " 'good' 'got' 'great' 'greatness' 'grosser' 'group' 'groups' 'half'\n",
      " 'happen' 'happens' 'harmon' 'hate' 'hear' 'highly' 'hope' 'human' 'idea'\n",
      " 'ideas' 'idiocy' 'improve' 'inferior' 'infinite' 'jim' 'job' 'john'\n",
      " 'journey' 'just' 'kim' 'large' 'lay' 'leave' 'let' 'life' 'light' 'like'\n",
      " 'live' 'll' 'look' 'lose' 'loss' 'lot' 'make' 'man' 'margaret' 'marion'\n",
      " 'maybe' 'mead' 'mean' 'meet' 'mile' 'minds' 'miss' 'motivated' 'mt'\n",
      " 'multitasking' 'muscles' 'neck' 'nerves' 'new' 'oh' 'opportunities'\n",
      " 'ordinary' 'pain' 'people' 'percentages' 'permission' 'person' 'positive'\n",
      " 'power' 'prejudice' 'private' 'proverb' 'public' 'purpose' 'pursue'\n",
      " 'quit' 'reach' 'reason' 'regarded' 'remember' 'rest' 'risk' 'rohn'\n",
      " 'roosevelt' 'sacrifices' 'safe' 'say' 'says' 'selling' 'serve' 'settle'\n",
      " 'shah' 'small' 'sound' 'speak' 'start' 'starts' 'step' 'stop' 'story'\n",
      " 'stupid' 'stupidity' 'succeed' 'success' 'successful' 'support' 'sure'\n",
      " 'swami' 'takers' 'talents' 'things' 'think' 'thomas' 'thought' 'thousand'\n",
      " 'thrown' 'time' 'today' 'tomorrow' 'travels' 'true' 'trust' 'try'\n",
      " 'turned' 'twice' 'underestimate' 'understand' 'unique' 'universe' 'use'\n",
      " 'useful' 'usual' 'vaibhav' 'value' 've' 'vivekananda' 'wait' 'walking'\n",
      " 'walt' 'want' 'warning' 'way' 'ways' 'widely' 'william' 'willing'\n",
      " 'winston' 'won' 'wooden' 'work' 'world' 'worry' 'wrong' 'yesterday']\n"
     ]
    }
   ],
   "source": [
    "print(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b21d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=f.Quotes\n",
    "y=f.Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42576c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d255aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e2a46b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\santh/nltk_data'\n    - 'C:\\\\Users\\\\santh\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\santh\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\santh\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\santh\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\santh/nltk_data'\n    - 'C:\\\\Users\\\\santh\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\santh\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\santh\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\santh\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1480\\625057419.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mfd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_review\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mX1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1480\\625057419.py\u001b[0m in \u001b[0;36mclean_review\u001b[1;34m(review)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclean_review\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mfiltered_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1480\\625057419.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclean_review\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mfiltered_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mlemma\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mword\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \"\"\"\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mlemmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\santh/nltk_data'\n    - 'C:\\\\Users\\\\santh\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\santh\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\santh\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\santh\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "def clean_review(review):\n",
    "    tokens = review.lower().split()\n",
    "    filtered_tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]\n",
    "    return \" \".join(filtered_tokens)\n",
    "sd=X.tolist()\n",
    "fd=[]\n",
    "for i in sd:\n",
    "    fd.append(clean_review(i))\n",
    "X1=pd.Series(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f17a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cfad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = tfidf.fit_transform(X1)\n",
    "features_names = tfidf.get_feature_names_out()\n",
    "text_vect = pd.DataFrame(vectors.todense(), columns=features_names)\n",
    "text_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f456a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(text_vect,y,train_size=0.75,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3281acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train,'\\n\\n\\n',X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f5a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train,'\\n\\n\\n',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92511721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d60d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee3e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c932fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1028, activation='relu',input_dim=X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3932c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(512, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7994547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(356, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab5c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6420f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79551206",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee9ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test loss:',loss, 'Test accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544161f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def build_model(input_dim, num_neurons):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_neurons, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dense(num_neurons // 2, activation='relu'))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066c0ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = [128, 256, 512, 1024]\n",
    "num_parameters = []\n",
    "training_accuracy = []\n",
    "testing_accuracy = []\n",
    "running_time = []\n",
    "\n",
    "for num_neurons in architectures:\n",
    "    model = build_model(X_train.shape[1], num_neurons)\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    end_time = time.time()\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    num_parameters.append(model.count_params())\n",
    "    training_accuracy.append(history.history['accuracy'][-1])\n",
    "    testing_accuracy.append(acc)\n",
    "    running_time.append(end_time - start_time)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.bar(architectures, num_parameters)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Number of Parameters')\n",
    "plt.title('Number of Parameters in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.bar(architectures, training_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Training Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.bar(architectures, testing_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.title('Testing Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.bar(architectures, running_time)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Running Time for Testing (seconds)')\n",
    "plt.title('Running Time for Testing in Different Architectures')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0113fc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a710578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(512, activation='relu'))\n",
    "model1.add(Dense(356, activation='relu'))\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "model1.add(Dense(16, activation='relu'))\n",
    "model1.add(Dense(8, activation='relu'))\n",
    "model1.add(Dense(2, activation='sigmoid'))\n",
    "model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "new_history = model1.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "new_loss, new_accuracy = model1.evaluate(X_test, y_test)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f05de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = [128, 256, 512]\n",
    "num_parameters = []\n",
    "training_accuracy = []\n",
    "testing_accuracy = []\n",
    "running_time = []\n",
    "\n",
    "for num_neurons in architectures:\n",
    "    model = build_model(X_train.shape[1], num_neurons)\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    end_time = time.time()\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    num_parameters.append(model.count_params())\n",
    "    training_accuracy.append(history.history['accuracy'][-1])\n",
    "    testing_accuracy.append(acc)\n",
    "    running_time.append(end_time - start_time)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.bar(architectures, num_parameters)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Number of Parameters')\n",
    "plt.title('Number of Parameters in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.bar(architectures, training_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Training Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.bar(architectures, testing_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.title('Testing Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.bar(architectures, running_time)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Running Time for Testing (seconds)')\n",
    "plt.title('Running Time for Testing in Different Architectures')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff33d65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938ee069",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(356, activation='relu'))\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dense(32, activation='relu'))\n",
    "model2.add(Dense(16, activation='relu'))\n",
    "model2.add(Dense(8, activation='relu'))\n",
    "model2.add(Dense(2, activation='sigmoid'))\n",
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "new_history = model2.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "new_loss, new_accuracy = model2.evaluate(X_test, y_test)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f69008",
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = [128, 256]\n",
    "num_parameters = []\n",
    "training_accuracy = []\n",
    "testing_accuracy = []\n",
    "running_time = []\n",
    "\n",
    "for num_neurons in architectures:\n",
    "    model = build_model(X_train.shape[1], num_neurons)\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    end_time = time.time()\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    num_parameters.append(model.count_params())\n",
    "    training_accuracy.append(history.history['accuracy'][-1])\n",
    "    testing_accuracy.append(acc)\n",
    "    running_time.append(end_time - start_time)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.bar(architectures, num_parameters)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Number of Parameters')\n",
    "plt.title('Number of Parameters in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.bar(architectures, training_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Training Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.bar(architectures, testing_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.title('Testing Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.bar(architectures, running_time)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Running Time for Testing (seconds)')\n",
    "plt.title('Running Time for Testing in Different Architectures')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce37d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc7242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "model3.add(Dense(64, activation='relu'))\n",
    "model3.add(Dense(32, activation='relu'))\n",
    "model3.add(Dense(16, activation='relu'))\n",
    "model3.add(Dense(8, activation='relu'))\n",
    "model3.add(Dense(2, activation='sigmoid'))\n",
    "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "new_history = model3.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "new_loss, new_accuracy = model3.evaluate(X_test, y_test)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad70d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = [128]\n",
    "num_parameters = []\n",
    "training_accuracy = []\n",
    "testing_accuracy = []\n",
    "running_time = []\n",
    "\n",
    "for num_neurons in architectures:\n",
    "    model = build_model(X_train.shape[1], num_neurons)\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    end_time = time.time()\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    num_parameters.append(model.count_params())\n",
    "    training_accuracy.append(history.history['accuracy'][-1])\n",
    "    testing_accuracy.append(acc)\n",
    "    running_time.append(end_time - start_time)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.bar(architectures, num_parameters)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Number of Parameters')\n",
    "plt.title('Number of Parameters in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.bar(architectures, training_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Training Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.bar(architectures, testing_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.title('Testing Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.bar(architectures, running_time)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Running Time for Testing (seconds)')\n",
    "plt.title('Running Time for Testing in Different Architectures')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ecb723",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858f689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(64, activation='relu'))\n",
    "model4.add(Dense(32, activation='relu'))\n",
    "model4.add(Dense(16, activation='relu'))\n",
    "model4.add(Dense(8, activation='relu'))\n",
    "model4.add(Dense(2, activation='sigmoid'))\n",
    "model4.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "new_history = model4.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "new_loss, new_accuracy = model4.evaluate(X_test, y_test)\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5772bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = []\n",
    "num_parameters = []\n",
    "training_accuracy = []\n",
    "testing_accuracy = []\n",
    "running_time = []\n",
    "\n",
    "for num_neurons in architectures:\n",
    "    model = build_model(X_train.shape[1], num_neurons)\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    end_time = time.time()\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    num_parameters.append(model.count_params())\n",
    "    training_accuracy.append(history.history['accuracy'][-1])\n",
    "    testing_accuracy.append(acc)\n",
    "    running_time.append(end_time - start_time)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.bar(architectures, num_parameters)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Number of Parameters')\n",
    "plt.title('Number of Parameters in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.bar(architectures, training_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Training Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.bar(architectures, testing_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.title('Testing Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.bar(architectures, running_time)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Running Time for Testing (seconds)')\n",
    "plt.title('Running Time for Testing in Different Architectures')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2d7a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7732a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Dense(32, activation='relu'))\n",
    "model5.add(Dense(16, activation='relu'))\n",
    "model5.add(Dense(8, activation='relu'))\n",
    "model5.add(Dense(2, activation='sigmoid'))\n",
    "model5.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "new_history = model5.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "new_loss, new_accuracy = model5.evaluate(X_test, y_test)\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd5673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = []\n",
    "num_parameters = []\n",
    "training_accuracy = []\n",
    "testing_accuracy = []\n",
    "running_time = []\n",
    "\n",
    "for num_neurons in architectures:\n",
    "    model = build_model(X_train.shape[1], num_neurons)\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    end_time = time.time()\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    num_parameters.append(model.count_params())\n",
    "    training_accuracy.append(history.history['accuracy'][-1])\n",
    "    testing_accuracy.append(acc)\n",
    "    running_time.append(end_time - start_time)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.bar(architectures, num_parameters)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Number of Parameters')\n",
    "plt.title('Number of Parameters in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.bar(architectures, training_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Training Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.bar(architectures, testing_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.title('Testing Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.bar(architectures, running_time)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Running Time for Testing (seconds)')\n",
    "plt.title('Running Time for Testing in Different Architectures')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e065d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7c1b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Dense(16, activation='relu'))\n",
    "model6.add(Dense(8, activation='relu'))\n",
    "model6.add(Dense(2, activation='sigmoid'))\n",
    "model6.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "new_history = model6.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "new_loss, new_accuracy = model6.evaluate(X_test, y_test)\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6202692",
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = []\n",
    "num_parameters = []\n",
    "training_accuracy = []\n",
    "testing_accuracy = []\n",
    "running_time = []\n",
    "\n",
    "for num_neurons in architectures:\n",
    "    model = build_model(X_train.shape[1], num_neurons)\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    end_time = time.time()\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    num_parameters.append(model.count_params())\n",
    "    training_accuracy.append(history.history['accuracy'][-1])\n",
    "    testing_accuracy.append(acc)\n",
    "    running_time.append(end_time - start_time)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.bar(architectures, num_parameters)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Number of Parameters')\n",
    "plt.title('Number of Parameters in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.bar(architectures, training_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Training Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.bar(architectures, testing_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.title('Testing Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.bar(architectures, running_time)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Running Time for Testing (seconds)')\n",
    "plt.title('Running Time for Testing in Different Architectures')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3e6a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbc9c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = Sequential()\n",
    "model7.add(Dense(8, activation='relu'))\n",
    "model7.add(Dense(2, activation='sigmoid'))\n",
    "model7.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "new_history = model7.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "new_loss, new_accuracy = model7.evaluate(X_test, y_test)\n",
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900cdc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = []\n",
    "num_parameters = []\n",
    "training_accuracy = []\n",
    "testing_accuracy = []\n",
    "running_time = []\n",
    "\n",
    "for num_neurons in architectures:\n",
    "    model = build_model(X_train.shape[1], num_neurons)\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    end_time = time.time()\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    num_parameters.append(model.count_params())\n",
    "    training_accuracy.append(history.history['accuracy'][-1])\n",
    "    testing_accuracy.append(acc)\n",
    "    running_time.append(end_time - start_time)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.bar(architectures, num_parameters)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Number of Parameters')\n",
    "plt.title('Number of Parameters in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.bar(architectures, training_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Training Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.bar(architectures, testing_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.title('Testing Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.bar(architectures, running_time)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Running Time for Testing (seconds)')\n",
    "plt.title('Running Time for Testing in Different Architectures')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e35c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cb2c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = Sequential()\n",
    "model8.add(Dense(2, activation='sigmoid'))\n",
    "model8.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "new_history = model8.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "new_loss, new_accuracy = model8.evaluate(X_test, y_test)\n",
    "model8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b286416",
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = []\n",
    "num_parameters = []\n",
    "training_accuracy = []\n",
    "testing_accuracy = []\n",
    "running_time = []\n",
    "\n",
    "for num_neurons in architectures:\n",
    "    model = build_model(X_train.shape[1], num_neurons)\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    end_time = time.time()\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    num_parameters.append(model.count_params())\n",
    "    training_accuracy.append(history.history['accuracy'][-1])\n",
    "    testing_accuracy.append(acc)\n",
    "    running_time.append(end_time - start_time)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.bar(architectures, num_parameters)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Number of Parameters')\n",
    "plt.title('Number of Parameters in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.bar(architectures, training_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Training Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.bar(architectures, testing_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.title('Testing Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.bar(architectures, running_time)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Running Time for Testing (seconds)')\n",
    "plt.title('Running Time for Testing in Different Architectures')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf1c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "model8.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312d5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = Sequential()\n",
    "model_.add(Dense(2048, activation='relu', input_dim=X_train.shape[1]))\n",
    "model_.add(Dense(1024, activation='relu'))\n",
    "model_.add(Dense(512, activation='relu'))\n",
    "model_.add(Dense(256, activation='relu'))\n",
    "model_.add(Dense(128, activation='relu'))\n",
    "model_.add(Dense(64, activation='relu'))\n",
    "model_.add(Dense(32, activation='relu'))\n",
    "model_.add(Dense(16, activation='relu'))\n",
    "model_.add(Dense(8, activation='relu'))\n",
    "model_.add(Dense(2, activation='sigmoid'))\n",
    "model_.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "new_history = model_.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "new_loss, new_accuracy = model_.evaluate(X_test, y_test)\n",
    "model_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194a78e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = [128, 256, 512, 1024]\n",
    "num_parameters = []\n",
    "training_accuracy = []\n",
    "testing_accuracy = []\n",
    "running_time = []\n",
    "\n",
    "for num_neurons in architectures:\n",
    "    model = build_model(X_train.shape[1], num_neurons)\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    end_time = time.time()\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    num_parameters.append(model.count_params())\n",
    "    training_accuracy.append(history.history['accuracy'][-1])\n",
    "    testing_accuracy.append(acc)\n",
    "    running_time.append(end_time - start_time)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.bar(architectures, num_parameters)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Number of Parameters')\n",
    "plt.title('Number of Parameters in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.bar(architectures, training_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Training Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.bar(architectures, testing_accuracy)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.title('Testing Accuracy in Different Architectures')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.bar(architectures, running_time)\n",
    "plt.xlabel('Number of Neurons in Hidden Layer')\n",
    "plt.ylabel('Running Time for Testing (seconds)')\n",
    "plt.title('Running Time for Testing in Different Architectures')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1b1650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8914f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"quotes.csv\")\n",
    "X = data['Quotes']\n",
    "y = data['Labels']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "X_train_tfidf = X_train_tfidf.toarray()\n",
    "X_val_tfidf = X_val_tfidf.toarray()\n",
    "X_test_tfidf = X_test_tfidf.toarray()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_dim=X_train_tfidf.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_tfidf, y_train, epochs=20, batch_size=32, validation_data=(X_val_tfidf, y_val))\n",
    "loss, accuracy = model.evaluate(X_test_tfidf, y_test)\n",
    "print('Test loss:', loss, 'Test accuracy:', accuracy)\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99ebf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d508aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a1271a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed32a803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aacf98c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71ee9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d367b114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c77d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac627c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0481395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532215a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3bfaa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2e5d81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
